{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YOU-nari/Stable-Diffusion-with-diffusers-Personal-modification-V3-github-/blob/main/Stable_Diffusion_with_%F0%9F%A7%A8_diffusers_Personal_modification_V3.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä¸Šã’ãŸã„æ™‚ã ã‘å®Ÿè¡Œ\n",
        "\n",
        "â€»ç¾çŠ¶ã¯å®Ÿè¡Œã™ã‚‹ã¨å‹•ã‹ãªããªã‚‹ã€‚\n",
        "\n",
        "å°†æ¥ä½¿ã†ã‹ã‚‚ã—ã‚Œãªã„ã®ã§ä¸€å¿œè¿½åŠ ã—ã¦ãŠã"
      ],
      "metadata": {
        "id": "odHVwbiCa0qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OSã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª\n",
        "!lsb_release -a"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xdqm5_4_PGFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ‘ã‚¹ç¢ºèª\n",
        "!echo $PYTHONPATH\n",
        "!python --version"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cyNINCcoP3pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ä½¿ã„ãŸã„Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®š\n",
        "targetPy:str=\"3.9\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "dzNPgYmsQPYi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Minicondaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "\n",
        "#@markdown [Minicondaã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸](https://docs.conda.io/en/latest/miniconda.html)ã«è¡Œãã€Linuxç”¨ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ã®åå‰ã¨URLã‚’ç¢ºèªã—ã¦ãŠãã€‚\n",
        "\n",
        "#@markdown ä»¥ä¸‹ã®ã‚»ãƒ«ã«ä»¥ä¸‹ã®ã‚ˆã†ã«è¨˜è¼‰ã™ã‚‹ï¼ˆ**ç©ºç™½å³ç¦**ï¼‰\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown - `MINOCONDA_INSTALLER`=`shãƒ•ã‚¡ã‚¤ãƒ«å`ã€€ï¼ˆã¨ã‚Šã‚ãˆãšã€æœ€æ–°ç‰ˆï¼‰\n",
        "#@markdown - `MINICONDA_DOWNLOAD_HP`=`URL`\n",
        "\n",
        "#@markdown ï¼ˆæœ€çµ‚ç¢ºèªï¼š2021/7/3ï¼‰\n",
        "%%bash\n",
        "MINICONDA_INSTALLER=Miniconda3-py39_4.12.0-Linux-x86_64.sh #@param {type:\"string\"}\n",
        "MINICONDA_DOWNLOAD_HP=https://repo.anaconda.com/miniconda #@param {type:\"string\"}\n",
        "\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget $MINICONDA_DOWNLOAD_HP/$MINICONDA_INSTALLER\n",
        "chmod +x $MINICONDA_INSTALLER\n",
        "./$MINICONDA_INSTALLER -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eP7qf_T9Q5x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦`conda ãƒãƒ¼ã‚¸ãƒ§ãƒ³`ãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰OK\n",
        "!conda -V"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n_mawP3gTJNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Minicondaã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ\n",
        "%%bash\n",
        "conda init bash\n",
        "conda update -n base -c defaults conda -y"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L3OQSsqIUaBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å¤‰æ›´ã¨ç¢ºèª\n",
        "!conda install python=$targetPy -y\n",
        "!python -V"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lNe9bX7SVuZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ¤œç´¢ã•ã›ã‚‹ãŸã‚ã«`sys.path`ã¸ãƒ‘ã‚¹ã‚’è¿½åŠ \n",
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python\"+targetPy+\"/site-packages\")\n",
        "sys.path"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cW_OMoX5V86X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ã“ã“ã¾ã§"
      ],
      "metadata": {
        "id": "eWv5VLqzhbE6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpvjXRDm_QQq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title åˆ©ç”¨å¯èƒ½ãªGPUã¨VRAMã®ç¢ºèª\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3PJ33S-Ktra"
      },
      "source": [
        "â†‘GPUãŒå‹•ãäº‹ç¢ºèªã—ã¦ã­     \n",
        "ã‚‚ã—å‹•ã„ã¦ãªã„å ´åˆã¯ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’GPUã«ã—ã¦ã­\n",
        "\n",
        "â†“diffusersãŒæ›´æ–°ã•ã‚ŒãŸã‚‰å¤‰æ›´ã—ã¦ã­\n",
        "ç¾æ™‚ç‚¹æœ€æ–°\n",
        "diffusion:1.5\n",
        "diffuser:0.7.2\n",
        "Waifu:1.3\n",
        "trinart:v2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title colaboã®æ®‹ã‚Šæ™‚é–“ç¢ºèª\n",
        "!cat /proc/uptime | awk '{printf(\"æ®‹ã‚Šæ™‚é–“ : %.2f\", 12-$1/60/60)}'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z0RjMtSqhiUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQEwlgJXKHmE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Stable Diffusion diffusersã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "\n",
        "!pip install -q diffusers==0.7.2 transformers scipy ftfy accelerate\n",
        "!pip install -q transformers scipy ftfy\n",
        "!pip install -q --upgrade diffusers[torch]\n",
        "\n",
        "#!huggingface-cli login\n",
        "#è‡ªåˆ†ã®ãƒˆãƒ¼ã‚¯ãƒ³è¨˜è¼‰ diffuser0.4.0ã‹ã‚‰ã¯1åº¦ãƒ­ã‚°ãƒ»ã‚¤ãƒ³ã™ã‚Œã°ä¸è¦ã‚‰ã—ã„\n",
        "#YOUR_TOKEN=\"\"\n",
        "!git clone https://github.com/openai/triton.git\n",
        "%cd triton/python/\n",
        "!pip install -q -e .\n",
        "!pip3 install -q --upgrade triton\n",
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title HuggingFaceğŸ¤—ã«ãƒ­ã‚°ã‚¤ãƒ³\n",
        "\n",
        "#markdown  https://huggingface.co/settings/tokens\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token"
      ],
      "metadata": {
        "id": "ps9nDqIAWyxQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz8TYP62PxF0"
      },
      "source": [
        "â†“SEEDã®ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã¨ã€Stable Diffusionãƒ¢ãƒ‡ãƒ«ã®é¸æŠã‚’è¿½åŠ \n",
        "ãƒ¢ãƒ‡ãƒ«ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹æ™‚ã¯\"ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®æ¥ç¶šã‚’è§£é™¤ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgw5A58WIkyc",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚„èª­è¾¼\n",
        "\n",
        "from transformers import CLIPTokenizer ,CLIPTextModel\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers.models import AutoencoderKL\n",
        "from diffusers import UNet2DConditionModel\n",
        "\n",
        "#ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”¨ã«ã€tokenizerã¨ã€text_encoderã‚’èª­ã¿è¾¼ã‚€\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "#SEEDã‚’ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã—ãŸã„ã®ã§è¿½åŠ \n",
        "import random\n",
        "\n",
        "#Xformersã®å®Ÿè£…ã‚’ã—ãŸã„ã‘ã©ã‚ˆãã‚ã‹ã‚‰ã‚“ãª\n",
        "#!sudo docker run -it --gpus=all --ipc=host -v /home:/home nvcr.io/nvidia/pytorch:22.08-py3 bash\n",
        "#!pip install --pre torch\n",
        "#!pip install xformers pytorch_lightning numpy\n",
        "#!pip3 install triton\n",
        "#!git clone https://github.com/openai/triton.git\n",
        "#%cd triton/python/\n",
        "#!pip install -e .\n",
        "\n",
        "#!pip install pytorch_lightning\n",
        "# Then \n",
        "# !pip install git+https://github.com/facebookresearch/xformers@51dd119#egg=xformers\n",
        "\n",
        "# Followed by\n",
        "#!cd PATH_TO_DIFFUSER_FOLDER\n",
        "#!git checkout memory_efficient_attention\n",
        "#  !pip install -e . \n",
        "\n",
        "#import math\n",
        "#import os\n",
        "\n",
        "#import pytorch_lightning as pl\n",
        "#import torch\n",
        "#import torch.nn as nn\n",
        "\n",
        "#from pytorch_lightning import Trainer, seed_everything\n",
        "#from pytorch_lightning.utilities import rank_zero_info\n",
        "#from torch.nn import functional as F\n",
        "#from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
        "\n",
        "#from xformers.factory.model_factory import xFormer, xFormerConfig\n",
        "\n",
        "#ã¨ã‚Šã‚ãˆãšã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã“ã‚Œå…¥ã‚Œã¨ãã‚ƒå‹•ãã‹ã‚‰ã„ã„ã‹\n",
        "#%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4, should also work on P100, thanks to https://github.com/metrolobo\n",
        "\n",
        "#@markdown Stable Diffusionãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ\n",
        "\n",
        "#@markdown 1:Normal 2:Waife 3:Trinart 4:Trinart-Waife-50-50\n",
        "model = 1 #@param {type:\"number\"}\n",
        "\n",
        "if model == 1:\n",
        " from diffusers import StableDiffusionPipeline , EulerAncestralDiscreteScheduler\n",
        "\n",
        "# pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=YOUR_TOKEN\n",
        "# ).to(\"cuda\")\n",
        "\n",
        "# æ½œåœ¨ç©ºé–“ã‚’ç”»åƒç©ºé–“ã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®VAEãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
        " #vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\",torch_dtype=torch.float16)\n",
        " vae = AutoencoderKL.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"vae\")\n",
        "\n",
        "# æ½œåœ¨ç©ºé–“ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®U-Netãƒ¢ãƒ‡ãƒ«ã®æŒ‡å®š\n",
        " unet = UNet2DConditionModel.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"unet\")\n",
        "\n",
        "# ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®æŒ‡å®š\n",
        " scheduler = (\"runwayml/stable-diffusion-v1-5\", subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\", scheduler=scheduler, torch_dtype=torch.float16 ,revision=\"fp16\", vae=vae,custom_pipeline=\"lpw_stable_diffusion\",\n",
        " ).to(\"cuda\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’GPUã¸ç§»ã™\n",
        " vae = vae.to(\"cuda\")\n",
        " text_encoder = text_encoder.to(\"cuda\")\n",
        " unet = unet.to(\"cuda\")\n",
        "\n",
        "#NSFWå›é¿å‡¦ç†\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Normal\")\n",
        "elif model == 2:\n",
        " from diffusers import StableDiffusionPipeline,LMSDiscreteScheduler #DDIMScheduler\n",
        "# StableDiffusionãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æº–å‚™ 1.3ã‹ã‚‰schedulerãŒå¤‰ã‚ã£ãŸã®ã§ã‚³ãƒ¡ãƒ³ãƒˆå‰ã®ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "     \"hakurei/waifu-diffusion\",\n",
        "     torch_dtype=torch.float32,\n",
        "     #revision=\"fp16\",\n",
        "     #scheduler=DDIMScheduler\n",
        "     scheduler=LMSDiscreteScheduler(\n",
        "         beta_start=0.00085,\n",
        "         beta_end=0.012,\n",
        "         beta_schedule=\"scaled_linear\",\n",
        "         #clip_sample=False,\n",
        "         #set_alpha_to_one=False,\n",
        "         num_train_timesteps=1000\n",
        "     ),\n",
        "     use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Waife\")\n",
        "elif model == 3:\n",
        " from diffusers import StableDiffusionPipeline\n",
        "\n",
        "# StableDiffusionãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æº–å‚™\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "     \"naclbit/trinart_stable_diffusion_v2\", \n",
        "     revision=\"diffusers-60k\",\n",
        "     use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Trinart\")\n",
        "elif model == 4:\n",
        " from diffusers import StableDiffusionPipeline\n",
        "\n",
        "# StableDiffusionãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æº–å‚™\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "     \"doohickey/trinart-waifu-diffusion-50-50\", \n",
        "     use_auth_token=YOUR_TOKEN\n",
        ").to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Trinart-Waifu-50-50\")\n",
        "else:\n",
        " print(\"å…¥åŠ›ã‚¨ãƒ©ãƒ¼:æ•°å€¤ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXi-LvVVJRCB"
      },
      "source": [
        "ã“ã“ã‹ã‚‰ä¸‹ã¯å¥½ãå‹æ‰‹ã„ã˜ã£ã¦éŠã¶ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGfmRXeVjGyJ"
      },
      "source": [
        "num_inference_stepsã¯1~200\n",
        "\n",
        "å›æ•°ãŒå¤šã„ç¨‹ç¶ºéº—ã«ãªã‚‹ãŒã€æ¥µç«¯ã«å¤§ããã—ã¦ã‚‚å¤‰ã‚ã‚‰ãªã„\n",
        "\n",
        "æ¨å¥¨å€¤ã¯50\n",
        "\n",
        "guidance_scaleã¯1~20\n",
        "\n",
        "æ•°å€¤ãŒå¤§ãã„ç¨‹Promptå†…å®¹ã«è¿‘ããªã‚‹ãŒå¤šæ§˜æ€§ãŒç„¡ããªã‚‹\n",
        "\n",
        "æ¨å¥¨å€¤ã¯7ã€œ8.5ãã‚‰ã„ã€30è¶…ãˆã‚‹ã¨ç ´ç¶»ã™ã‚‹\n",
        "\n",
        "batch_size å¢—ã‚„ã™ã¨æ–½è¡Œæ•°ãŒå¢—ãˆã‚‹?\n",
        "\n",
        "å®Ÿè¡Œé€Ÿåº¦ã‚‚ä¸ŠãŒã‚‹ãŒVRAMã‚’å¤§é‡ã«æ¶ˆè²»"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8tPqDxHJX9i",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title å¤‰æ•°ã®è¨­å®š\n",
        "\n",
        "#å¤‰æ•°å®£è¨€\n",
        "num_inference_steps = 10     #@param {type:\"number\"}      # Number of denoising steps\n",
        "guidance_scale = 7        #@param {type:\"number\"}       # Scale for classifier-free guidance\n",
        "#batch_size = 2 #@param {type:\"number\"}\n",
        "# ç”»åƒã®ã‚µã‚¤ã‚º 512*512ãŒåˆæœŸå€¤\n",
        "height = 512        #@param {type:\"number\"}              # default height of Stable Diffusion\n",
        "width = 512             #@param {type:\"number\"}          # default width of Stable Diffusion\n",
        "#batch_size = 1 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title æç”»æŒ‡ç¤º\n",
        "\n",
        "#å…¥åŠ›æ–‡å­— ã“ã“ã«å¥½ããªç¦å‰‡æ–‡å­—ã‚’ã„ã‚Œã¦ãã ã•ã„\n",
        "\n",
        "prompt = \"masterpiece, insane detaled, best quality, A woman in a luxury dress with long hair with a beautiful and perfect symmetrical face blonde loose perm by mucha\" #@param {type:\"string\"}\n",
        "\n",
        "#ãƒã‚¬ãƒ†ã‚£ãƒ– é™¤å¤–ã—ãŸã„è¦ç´ ã‚’å…¥ã‚Œã‚‹\n",
        "\n",
        "negative_prompt = \"pablo picasso,monet,dali,van gogh,\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "gwE8DaQ24Z0M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j8-Yu00JGMA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ç”»åƒç”Ÿæˆå›æ•°ã¨SEEDã®ç¨®åˆ¥\n",
        "\n",
        "N = 1 #@param {type:\"number\"}\n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'}\n",
        "for i in range(N):\n",
        "# SEEDå€¤ã€ã“ã“ã‚’ã‹ãˆã‚‹ã¨ åŒã˜å…¥åŠ›æ–‡å­—ã§ã‚‚åˆ¥ã®ç”»åƒãŒã§ã¾ã™\n",
        "# seedã‚’å›ºå®šã™ã‚‹æ™‚ã¯seed_fixã«ãƒã‚§ãƒƒã‚¯\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "  #VRAMæ¶ˆè²»ã‚’æŠ‘ãˆãŸã„å ´åˆæœ‰åŠ¹ã«â†“\n",
        "    pipe.enable_attention_slicing()\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    with torch.inference_mode():\n",
        "    #images = pipe(prompt, height = height, width = width, guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,negative_prompt = negative_prompt, generator = generator).images\n",
        "     images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples = 8,generator = generator).images\n",
        "#ã©ã®SEEDå€¤ã§æç”»ã•ã‚ŒãŸã‹ç¢ºèªç”¨\n",
        "     print(\"SEED =\",seed)\n",
        "     display(images[0])#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06TWdF3JQaA"
      },
      "source": [
        "ã‚‚ã£ã¨è©³ã—ãçŸ¥ã‚ŠãŸã„äººã¯\n",
        "https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb#scrollTo=zHkHsdtnry57\n",
        "ã“ã£ã¡ã®ã¡ã‚ƒã‚“ã¨ã—ãŸcolabã‚’è¦‹ã‚‹ã‚“ã ï¼ï¼ï¼ï¼"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhfQ4GLv39K3"
      },
      "source": [
        "â†“Waifuå˜ç‹¬å‹•ä½œ\n",
        "\n",
        "ã“ã“ã‹ã‚‰å‹•ã‹ã›ã°è‰¯ã„ã€‚\n",
        "ç‰¹ã«2æ¬¡å…ƒã¯WifuãŒåœ§å€’çš„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye_11709e3Y0"
      },
      "outputs": [],
      "source": [
        " #@title Waifu Diffusionã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨è¨­å®š\n",
        "!pip install -q diffusers==0.7.2 transformers scipy ftfy accelerate\n",
        "!pip install -q transformers scipy ftfy\n",
        "!pip install -q --upgrade diffusers[torch]\n",
        "\n",
        "from transformers import CLIPTokenizer ,CLIPTextModel\n",
        "\n",
        "#ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”¨ã«ã€tokenizerã¨ã€text_encoderã‚’èª­ã¿è¾¼ã‚€\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "\n",
        "#Xformersã®å®Ÿè£…ã‚’ã—ãŸã„ã‘ã©ã‚ˆãã‚ã‹ã‚‰ã‚“ãª\n",
        "# !sudo docker run -it --gpus=all --ipc=host -v /home:/home nvcr.io/nvidia/pytorch:22.08-py3 bash\n",
        "\n",
        "# Then \n",
        "# !pip install git+https://github.com/facebookresearch/xformers@51dd119#egg=xformers\n",
        "\n",
        "# Followed by\n",
        "# !cd PATH_TO_DIFFUSER_FOLDER\n",
        "# !git checkout memory_efficient_attention\n",
        "# !pip install -e . \n",
        "!git clone https://github.com/openai/triton.git\n",
        "%cd triton/python/\n",
        "!pip install -q -e .\n",
        "!pip3 install -q --upgrade triton\n",
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "#!pip install pytorch_lightning\n",
        "#ã¨ã‚Šã‚ãˆãšã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã“ã‚Œå…¥ã‚Œã¨ãã‚ƒå‹•ãã‹ã‚‰ã„ã„ã‹\n",
        "#!pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4, should also work on P100, thanks to https://github.com/metrolobo\n",
        "\n",
        "#ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã—ãŸã„ã®ã§è¿½åŠ \n",
        "import random\n",
        "import torch\n",
        "\n",
        "from diffusers.models import AutoencoderKL\n",
        "from diffusers import UNet2DConditionModel\n",
        "\n",
        "from torch import autocast\n",
        "#from diffusers import DiffusionPipeline\n",
        " from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler #DDIMScheduler\n",
        "# StableDiffusionãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æº–å‚™\n",
        "# pipe = StableDiffusionPipeline.from_pretrained(\n",
        "#  \"hakurei/waifu-diffusion\",\n",
        "#  torch_dtype=torch.float32,\n",
        "  #revision=\"fp16\",#â†æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å»ƒæ­¢ã•ã‚Œã¦ã‚‹\n",
        "  #scheduler=DDIMScheduler(\n",
        "#vae = AutoencoderKL.from_pretrained(\"waifu-diffusion-v1-4/vae/kl-f8-anime.ckpt\")â†ä»® 1.4ãƒªãƒªãƒ¼ã‚¹æ™‚ã«ç¢ºèª\n",
        "vae = AutoencoderKL.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"vae\")\n",
        "unet = UNet2DConditionModel.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"unet\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    'hakurei/waifu-diffusion',   \n",
        "    custom_pipeline=\"lpw_stable_diffusion\",\n",
        "    #revision=\"fp32\",\n",
        "    torch_dtype=torch.float32,#vae=vae,\n",
        "  scheduler=LMSDiscreteScheduler(\n",
        "         beta_start=0.00085,\n",
        "         beta_end=0.012,\n",
        "         beta_schedule=\"scaled_linear\",\n",
        "         #.clip_sample=False,\n",
        "         #set_alpha_to_one=False,\n",
        "         num_train_timesteps=1000\n",
        "     ),\n",
        "     #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " vae = vae.to(\"cuda\")\n",
        " text_encoder = text_encoder.to(\"cuda\")\n",
        " unet = unet.to(\"cuda\")\n",
        "#NSFWå›é¿å‡¦ç†\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "#VRAMä½æ¶ˆè²»â€»å°‘ã—å®Ÿè¡Œé€Ÿåº¦ãŒè½ã¡ã‚‹\n",
        "#pipe.enable_attention_slicing()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJTIRKLa_yfl"
      },
      "source": [
        "GUIã§ãªãCUIã§å‹•ãã‚ˆã†ã«ç›´ã—ãŸã€‚\n",
        "ãƒ«ãƒ¼ãƒ—çµ„ã‚“ã§æŒ‡å®šã—ãŸå›æ•°å®Ÿè¡Œã—ç¶šã‘ã‚‹ã®ã§ã“ã£ã¡ã®ã»ã†ãŒä½¿ã„å‹æ‰‹ã‚ˆã„ã€‚\n",
        "ãƒ©ãƒ³ã‚¿ã‚¤ãƒ åˆ‡æ–­ã§ã‚‚å†èµ·å‹•å¾Œç¶™ç¶šã™ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "num_inference_stepsã¯1~200\n",
        "\n",
        "å›æ•°ãŒå¤šã„ç¨‹ç¶ºéº—ã«ãªã‚‹ãŒã€æ¥µç«¯ã«å¤§ããã—ã¦ã‚‚å¤‰ã‚ã‚‰ãªã„\n",
        "\n",
        "æ¨å¥¨å€¤ã¯50\n",
        "\n",
        "guidance_scaleã¯1~20\n",
        "\n",
        "æ•°å€¤ãŒå¤§ãã„ç¨‹Promptå†…å®¹ã«è¿‘ããªã‚‹ãŒå¤šæ§˜æ€§ãŒç„¡ããªã‚‹\n",
        "\n",
        "æ¨å¥¨å€¤ã¯7ã€œ8.5ãã‚‰ã„ã€30è¶…ãˆã‚‹ã¨ç ´ç¶»ã™ã‚‹\n",
        "\n",
        "batch_size å¢—ã‚„ã™ã¨æ–½è¡Œæ•°ãŒå¢—ãˆã‚‹?\n",
        "\n",
        "å®Ÿè¡Œé€Ÿåº¦ã‚‚ä¸ŠãŒã‚‹ãŒVRAMã‚’å¤§é‡ã«æ¶ˆè²»\n",
        "\n",
        "åŸºæœ¬çš„ã«ã¯512Ã—512ãŒ1ç•ªè‰¯ã„çµæœãŒå‡ºã‚‹\n",
        "\n",
        "guidance_scale 1~30 å¤§ãã„ç¨‹promptã«è¿‘ã„ç”»åƒã«ãªã‚‹ãŒå¤šæ§˜æ€§ã¯ç„¡ããªã‚‹"
      ],
      "metadata": {
        "id": "YDOetnwC1w1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title å¤‰æ•°ã®è¨­å®š\n",
        "\n",
        "#å¤‰æ•° åˆæœŸå€¤ 512*512 scale:6 step:50\n",
        "height = 768 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "guidance_scale = 12 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "#batch_size = 1 #@param {type:\"number\"}\n",
        "#num_samples = 1 ã“ã‚Œã¯ [prompt] * num_samplesã§å…¥ã‚Œå­ã«æŒ‡å®šå›æ•°åˆ†å‡ºåŠ›"
      ],
      "metadata": {
        "id": "gPL1RDhR0X_8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title æç”»æŒ‡ç¤º\n",
        "prompt = \"masterpiece, best quality, nsfw, uncensored, masterpiece, Insane detaled, watercolor 1, pastel colors, pov, looking at viewer, 1girl, solo, gsmell, (dwarf woman), fat, plump, very ugly, mature female, muscular female, looks 10 yo, cute dog ears, chonky female, fluffy, beautiful scarlet curl longhair, luxury naughty panty, luxury naughty bra, black pantyhose, panties over pantyhose, dog tail, animal tail, animal ears, animal hands, animal ears fluff, thick thighs, huge ass, huge breasts, huge nipples, puffy nipples, dark nipples, inverted nipples, anus, anal hair, many facial, many pubic hair, female orgasm, many pussy juice, spread pussy,reverse cowgirl position, spread legs, many cum in pussy, many cum on hair, many cum on body, many cum in mouth, breast grab, paizuri, fellatio, she is insert huge veiny penis, precum, he is ejaculating, she looks in agony, she looks painful, she has teary eyes, she looks hates, rape, sex, hetero, anal, vaginal, in a public Park\" #@param {type:\"string\"}\n",
        "\n",
        "negative_prompt = \"censored, pablo picasso, poorly drawn, ((futanari)), ((futa with female)), ((futa with futa)), ((futa with male)), ((2girls)), ((multiple girls)), ((multiple body)), ((multiple thighs)), ((multiple crotches)), ((multiple pussy)), ((multiple breasts)), ((multiple legs)), ((multiple ass)), ((multiple fingers )), (bad anatomy), the background is incoherent, more than 2 thighs, huge thighs, huge calf, missing hand, disappearing arms, disappearing thigh, disappearing calf, disappearing legs, missing fingers, one hand with more than 5 fingers, one hand with less than 5 fingers, extra digits, extra arms, extra legs, extra fingers extra penises, extra testicles, missing arms, missing legs, missing fingers, missing asshole, fused fingers, fused hand, fused asshole, fused arms, fused legs, fused fingers, fused anus, fused pussy, bad hands, bad asshole, bad anus, bad pussy, bad crotch, bad crotch seam, bad feet, (abnormal eye proportion:1.2), (Abnormal hands), (abnormal legs), (abnormal feet), image macro, ranguage, watermark, watermarked, long head, long body, mutated hands and fingers, speech bubble, blank speech bubble, shared speech bubble, speech stab, sound effects, typo, anatomical nonsense, quality, solid color thumbnail, fewer digits, lowres, worst quality, low quality, normal quality, jpeg artifacts, signature, username, blurry, text, error, (face out of frame), (cropped), black and white painting, black-white, monochrome, monotone, greyscale, lineart, retro style, 1980s, 1990s, comic, artist name, canvas, art frame low resolution, low detail, out of focus, bad framing, tiling\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "LdLCkaac0sN_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Dc8wK6oTpRt"
      },
      "outputs": [],
      "source": [
        "8#@title ãƒ«ãƒ¼ãƒ—å›æ•°\n",
        "N = 1 #@param {type:\"number\"}\n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'} \n",
        "#ãƒ«ãƒ¼ãƒ—å‡¦ç†\n",
        "for i in range(N):\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "    pipe.enable_attention_slicing()\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    with torch.inference_mode():\n",
        "    #images = pipe(prompt, height = height, width = width, guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,negative_prompt = negative_prompt, generator = generator).images\n",
        "     images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples=8,generator = generator).images[0]\n",
        "\n",
        "#ã©ã®SEEDå€¤ã§æç”»ã•ã‚ŒãŸã‹ç¢ºèªç”¨\n",
        "     print(\"SEED =\",seed)\n",
        "     display(images)#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Gdriveã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­è¾¼ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã„\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!python -m venv .env\n",
        "\n",
        "!source .env/bin/activate\n",
        "\n",
        "!pip install diffusers==0.7.1 transformers scipy ftfy accelerate\n",
        "!pip install --upgrade diffusers transformers scipy\n",
        "#!huggingface-cli login\n",
        "import torch\n",
        "from torch import autocast\n",
        "# secretAI\n",
        "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
        "\n",
        "euler_ancestral_scheduler = EulerAncestralDiscreteScheduler.from_config(\"content/drive/MyDrive/model/novelAI.ckpt\", subfolder=\"scheduler\")\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "    \"content/drive/MyDrive/model/novelAI.ckpt\",torch_dtype=torch.float16, custom_pipeline=\"lpw_stable_diffusion\", scheduler=euler_scheduler, use_auth_token=YOUR_TOKEN,\n",
        ")\n",
        "pipeline.to(\"cuda\")"
      ],
      "metadata": {
        "id": "Z5cLeoAiY_fr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}