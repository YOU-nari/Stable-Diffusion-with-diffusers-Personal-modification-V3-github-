{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YOU-nari/Stable-Diffusion-with-diffusers-Personal-modification-V3-github-/blob/main/Stable_Diffusion_with_%F0%9F%A7%A8_diffusers_Personal_modification_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpvjXRDm_QQq"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3PJ33S-Ktra"
      },
      "source": [
        "↑GPUが動く事確認してね     \n",
        "もし動いてない場合は ランタイムのタイプをGPUにしてね\n",
        "\n",
        "↓diffusersが更新されたら変更してね\n",
        "現時点最新\n",
        "diffusion:1.5(関係者からのリークを公開したらしい)\n",
        "diffuser:0.6.0\n",
        "Waifu:1.3\n",
        "trinart:v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQEwlgJXKHmE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Stable Diffusion diffusersをロード\n",
        "\n",
        "!pip install diffusers==0.6.0 transformers scipy ftfy\n",
        "\n",
        "#自分のトークン記載 diffuser0.4.0からは1度ログ・インすれば不要らしい\n",
        "YOUR_TOKEN=\"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz8TYP62PxF0"
      },
      "source": [
        "↓SEEDのランダム化と、Stable Diffusionモデルの選択を追加\n",
        "モデルを切り替える時は\"ランタイムの接続を解除してから再実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgw5A58WIkyc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title このセルは一回だけ実行で良い、色々DLしてきます\n",
        "import torch\n",
        "from torch import autocast\n",
        "#SEEDをランダム化したいので追加\n",
        "import random\n",
        "\n",
        "#@markdown Stable Diffusionモデルを選択 \n",
        "\n",
        "#@markdown 1:Normal 2:Waife 3:Trinart 4:Trinart-Waife-50-50\n",
        "model = 1 #@param {type:\"number\"}\n",
        "\n",
        "if model == 1:\n",
        " from diffusers import StableDiffusionPipeline\n",
        "\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        "#NSFW回避処理\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Normal\")\n",
        "elif model == 2:\n",
        " from diffusers import StableDiffusionPipeline,LMSDiscreteScheduler #DDIMScheduler\n",
        "# StableDiffusionパイプラインの準備 1.3からschedulerが変わったのでコメント前のはコメントアウト\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "     \"hakurei/waifu-diffusion\",\n",
        "     torch_dtype=torch.float32,\n",
        "     #revision=\"fp16\",\n",
        "     #scheduler=DDIMScheduler(\n",
        "     scheduler=LMSDiscreteScheduler(\n",
        "         beta_start=0.00085,\n",
        "         beta_end=0.012,\n",
        "         beta_schedule=\"scaled_linear\",\n",
        "         #clip_sample=False,\n",
        "         #set_alpha_to_one=False,\n",
        "         num_train_timesteps=1000\n",
        "     ),\n",
        "     use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Waife\")\n",
        "elif model == 3:\n",
        " from diffusers import StableDiffusionPipeline\n",
        "\n",
        "# StableDiffusionパイプラインの準備\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "     \"naclbit/trinart_stable_diffusion_v2\", \n",
        "     revision=\"diffusers-60k\",\n",
        "     use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Trinart\")\n",
        "elif model == 4:\n",
        " from diffusers import StableDiffusionPipeline\n",
        "\n",
        "# StableDiffusionパイプラインの準備\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "     \"doohickey/trinart-waifu-diffusion-50-50\", \n",
        "     use_auth_token=YOUR_TOKEN\n",
        ").to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Trinart-Waifu-50-50\")\n",
        "else:\n",
        " print(\"入力エラー:数値を見直してください。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXi-LvVVJRCB"
      },
      "source": [
        "ここから下は好き勝手いじって遊ぶためのパラメーター"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGfmRXeVjGyJ"
      },
      "source": [
        "num_inference_stepsは1~200\n",
        "\n",
        "回数が多い程綺麗になるが、極端に大きくしても変わらない\n",
        "\n",
        "推奨値は50\n",
        "\n",
        "guidance_scaleは1~20\n",
        "\n",
        "数値が大きい程Prompt内容に近くなるが多様性が無くなる\n",
        "\n",
        "推奨値は7〜8.5くらい、30超えると破綻する\n",
        "\n",
        "batch_size 増やすと施行数が増える?\n",
        "\n",
        "実行速度も上がるがVRAMを大量に消費"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8tPqDxHJX9i",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#変数宣言 何故かstepsは+1される\n",
        "num_inference_steps = 50     #@param {type:\"number\"}      # Number of denoising steps\n",
        "guidance_scale = 7.5        #@param {type:\"number\"}       # Scale for classifier-free guidance\n",
        "batch_size = 1 #@param {type:\"number\"}\n",
        "# 画像のサイズ 512*512が初期値\n",
        "height = 512        #@param {type:\"number\"}              # default height of Stable Diffusion\n",
        "width = 512             #@param {type:\"number\"}            # default width of Stable Diffusion\n",
        "#@markdown ループ回数指定\n",
        "N = 1 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#入力文字 ここに好きな禁則文字をいれてください\n",
        "\n",
        "prompt = \"naked beautiful woman,Both hands behind the hed,Squatting\" #@param {type:\"string\"}\n",
        "\n",
        "#ネガティブ 除外したい要素を入れる\n",
        "\n",
        "negative_prompt = \"public hair\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "gwE8DaQ24Z0M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j8-Yu00JGMA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        ",#@title ループ処理\n",
        "N = 1 #@param {type:\"number\"}\n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'}\n",
        "for i in range(N):\n",
        "# SEED値、ここをかえると 同じ入力文字でも別の画像がでます\n",
        "# seedを固定する時はseed_fixにチェック\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "  #VRAM消費を抑えたい場合有効に↓\n",
        "    pipe.enable_attention_slicing()\n",
        "    images = pipe(prompt, negative_prompt = negative_prompt, height = height, width = width, guidance_scale = guidance_scale , num_inference_steps = num_inference_steps, generator = generator,batch_size = batch_size).images\n",
        "   #どのSEED値で描画されたか確認用\n",
        "    print(\"SEED =\",seed)\n",
        "    display(images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06TWdF3JQaA"
      },
      "source": [
        "もっと詳しく知りたい人は\n",
        "https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb#scrollTo=zHkHsdtnry57\n",
        "こっちのちゃんとしたcolabを見るんだ！！！！\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhfQ4GLv39K3"
      },
      "source": [
        "↓Waifu単独動作\n",
        "\n",
        "ここから動かせば良い。\n",
        "特に2次元はWifuが圧倒的"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye_11709e3Y0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        " #@title Waifu Diffusionのダウンロードと設定\n",
        " !pip install diffusers==0.6.0 transformers scipy ftfy\n",
        "#SEEDをランダム化したいので追加\n",
        "import random\n",
        "import torch\n",
        "from torch import autocast\n",
        " from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler #DDIMScheduler\n",
        "# StableDiffusionパイプラインの準備\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "  \"hakurei/waifu-diffusion\",\n",
        "  torch_dtype=torch.float32,\n",
        "  #revision=\"fp16\",#←最新バージョンで廃止されてる\n",
        "  #scheduler=DDIMScheduler(\n",
        "  scheduler=LMSDiscreteScheduler(\n",
        "         beta_start=0.00085,\n",
        "         beta_end=0.012,\n",
        "         beta_schedule=\"scaled_linear\",\n",
        "         #.clip_sample=False,\n",
        "         #set_alpha_to_one=False,\n",
        "         num_train_timesteps=1000\n",
        "     ),\n",
        "     #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        "#NSFW回避処理\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "#VRAM低消費※少し実行速度が落ちる\n",
        "#pipe.enable_attention_slicing()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJTIRKLa_yfl"
      },
      "source": [
        "GUIでなくCUIで動くように直した。\n",
        "ループ組んで指定した回数実行し続けるのでこっちのほうが使い勝手よい。\n",
        "ランタイム切断でも再起動後継続する。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "num_inference_stepsは1~200\n",
        "\n",
        "回数が多い程綺麗になるが、極端に大きくしても変わらない\n",
        "\n",
        "推奨値は50\n",
        "\n",
        "guidance_scaleは1~20\n",
        "\n",
        "数値が大きい程Prompt内容に近くなるが多様性が無くなる\n",
        "\n",
        "推奨値は7〜8.5くらい、30超えると破綻する\n",
        "\n",
        "batch_size 増やすと施行数が増える?\n",
        "\n",
        "実行速度も上がるがVRAMを大量に消費\n",
        "\n",
        "基本的には512×512が1番良い結果が出る\n",
        "\n",
        "guidance_scale 1~30 大きい程promptに近い画像になるが多様性は無くなる"
      ],
      "metadata": {
        "id": "YDOetnwC1w1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#変数 初期値 512*512 scale:6 step:50\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "guidance_scale = 6 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "batch_size = 1 #@param {type:\"number\"}\n",
        "#num_samples = 1 これは [prompt] * num_samplesで入れ子に指定回数分出力"
      ],
      "metadata": {
        "id": "gPL1RDhR0X_8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"1girl,1boy ,pov,watercolor,pastel colors, chubby man and Forties,very ugly mature  female dog ear Dwarf,beautiful scarlet loose long hair , pubic hair,huage ass ,huage  Breast ,huage puffy nipples,inverted nipples ,spread stinky pussy,anus,cowgirl position ,hetero,sex\" #@param {type:\"string\"}\n",
        "\n",
        "negative_prompt = \" censored,speech bubble,sound  effect,typo,image macro ,anatomical nonsense, bad anatomy, bad feet ,bad hands ,quality, ranguage,solid color thumbnail , watermark,text , multiple ass and hand and fingers and arms and Breasts and Thigh and Crotch and pussy and body,Artifacts,artest name\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "LdLCkaac0sN_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Dc8wK6oTpRt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ループ回数\n",
        "N = 5 #@param {type:\"number\"}\n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'} \n",
        "#ループ処理\n",
        "for i in range(N):\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "    pipe.enable_attention_slicing()\n",
        "    images = pipe(prompt, height = height, width = width, guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,negative_prompt = negative_prompt, generator = generator).images\n",
        "#どのSEED値で描画されたか確認用\n",
        "    print(\"SEED =\",seed)\n",
        "    display(images[0])#.save(f'output{i}.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}