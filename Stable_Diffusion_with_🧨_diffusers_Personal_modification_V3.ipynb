{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YOU-nari/Stable-Diffusion-with-diffusers-Personal-modification-V3-github-/blob/main/Stable_Diffusion_with_%F0%9F%A7%A8_diffusers_Personal_modification_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpvjXRDm_QQq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title GPUの確認\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3PJ33S-Ktra"
      },
      "source": [
        "↑GPUが動く事確認してね     \n",
        "もし動いてない場合は ランタイムのタイプをGPUにしてね\n",
        "\n",
        "↓diffusersが更新されたら変更してね\n",
        "現時点最新\n",
        "diffusion:1.5\n",
        "diffuser:0.7.2\n",
        "Waifu:1.3\n",
        "trinart:v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQEwlgJXKHmE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Stable Diffusion diffusersをロード\n",
        "\n",
        "#!pip install diffusers==0.7.2 transformers scipy ftfy accelerater\n",
        "!pip install transformers scipy ftfy\n",
        "!pip install --upgrade diffusers[torch]\n",
        "#!huggingface-cli login\n",
        "#自分のトークン記載 diffuser0.4.0からは1度ログ・インすれば不要らしい\n",
        "#YOUR_TOKEN=\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hugging Faceにログインする\n",
        "#colabだとこの方法じゃないと駄目らしい\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "ps9nDqIAWyxQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz8TYP62PxF0"
      },
      "source": [
        "↓SEEDのランダム化と、Stable Diffusionモデルの選択を追加\n",
        "モデルを切り替える時は\"ランタイムの接続を解除してから再実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgw5A58WIkyc",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title このセルは一回だけ実行で良い、色々DLしてきます\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers.models import AutoencoderKL\n",
        "\n",
        "#SEEDをランダム化したいので追加\n",
        "import random\n",
        "\n",
        "#Xformersの実装をしたいけどよくわからんな\n",
        "#!sudo docker run -it --gpus=all --ipc=host -v /home:/home nvcr.io/nvidia/pytorch:22.08-py3 bash\n",
        "#!pip install --pre torch\n",
        "#!pip install xformers pytorch_lightning numpy\n",
        "#!pip3 install triton\n",
        "!git clone https://github.com/openai/triton.git\n",
        "%cd triton/python/\n",
        "!pip install -e .\n",
        "\n",
        "!pip install pytorch_lightning\n",
        "# Then \n",
        "# !pip install git+https://github.com/facebookresearch/xformers@51dd119#egg=xformers\n",
        "\n",
        "# Followed by\n",
        "#!cd PATH_TO_DIFFUSER_FOLDER\n",
        "#!git checkout memory_efficient_attention\n",
        "#  !pip install -e . \n",
        "\n",
        "#import math\n",
        "#import os\n",
        "\n",
        "#import pytorch_lightning as pl\n",
        "#import torch\n",
        "#import torch.nn as nn\n",
        "\n",
        "#from pytorch_lightning import Trainer, seed_everything\n",
        "#from pytorch_lightning.utilities import rank_zero_info\n",
        "#from torch.nn import functional as F\n",
        "#from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
        "\n",
        "#from xformers.factory.model_factory import xFormer, xFormerConfig\n",
        "\n",
        "#とりあえずコンパイル済みこれ入れときゃ動くからいいか\n",
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4, should also work on P100, thanks to https://github.com/metrolobo\n",
        "\n",
        "#@markdown Stable Diffusionモデルを選択\n",
        "\n",
        "#@markdown 1:Normal 2:Waife 3:Trinart 4:Trinart-Waife-50-50\n",
        "model = 1 #@param {type:\"number\"}\n",
        "\n",
        "if model == 1:\n",
        " from diffusers import StableDiffusionPipeline , EulerAncestralDiscreteScheduler\n",
        "\n",
        "# pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=YOUR_TOKEN\n",
        "# ).to(\"cuda\")\n",
        " vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\")\n",
        " euler_scheduler = EulerAncestralDiscreteScheduler.from_config(\"runwayml/stable-diffusion-v1-5\", subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\", scheduler=euler_scheduler, torch_dtype=torch.float16 ,revision=\"fp16\", vae=vae,custom_pipeline=\"lpw_stable_diffusion\",\n",
        " ).to(\"cuda\")\n",
        "#NSFW回避処理\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Normal\")\n",
        "elif model == 2:\n",
        " from diffusers import StableDiffusionPipeline,LMSDiscreteScheduler #DDIMScheduler\n",
        "# StableDiffusionパイプラインの準備 1.3からschedulerが変わったのでコメント前のはコメントアウト\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "     \"hakurei/waifu-diffusion\",\n",
        "     torch_dtype=torch.float32,\n",
        "     #revision=\"fp16\",\n",
        "     #scheduler=DDIMScheduler\n",
        "     scheduler=LMSDiscreteScheduler(\n",
        "         beta_start=0.00085,\n",
        "         beta_end=0.012,\n",
        "         beta_schedule=\"scaled_linear\",\n",
        "         #clip_sample=False,\n",
        "         #set_alpha_to_one=False,\n",
        "         num_train_timesteps=1000\n",
        "     ),\n",
        "     use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Waife\")\n",
        "elif model == 3:\n",
        " from diffusers import StableDiffusionPipeline\n",
        "\n",
        "# StableDiffusionパイプラインの準備\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "     \"naclbit/trinart_stable_diffusion_v2\", \n",
        "     revision=\"diffusers-60k\",\n",
        "     use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Trinart\")\n",
        "elif model == 4:\n",
        " from diffusers import StableDiffusionPipeline\n",
        "\n",
        "# StableDiffusionパイプラインの準備\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "     \"doohickey/trinart-waifu-diffusion-50-50\", \n",
        "     use_auth_token=YOUR_TOKEN\n",
        ").to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Trinart-Waifu-50-50\")\n",
        "else:\n",
        " print(\"入力エラー:数値を見直してください。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXi-LvVVJRCB"
      },
      "source": [
        "ここから下は好き勝手いじって遊ぶためのパラメーター"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGfmRXeVjGyJ"
      },
      "source": [
        "num_inference_stepsは1~200\n",
        "\n",
        "回数が多い程綺麗になるが、極端に大きくしても変わらない\n",
        "\n",
        "推奨値は50\n",
        "\n",
        "guidance_scaleは1~20\n",
        "\n",
        "数値が大きい程Prompt内容に近くなるが多様性が無くなる\n",
        "\n",
        "推奨値は7〜8.5くらい、30超えると破綻する\n",
        "\n",
        "batch_size 増やすと施行数が増える?\n",
        "\n",
        "実行速度も上がるがVRAMを大量に消費"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8tPqDxHJX9i",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 変数の設定\n",
        "\n",
        "#変数宣言 何故かstepsは+1される\n",
        "num_inference_steps = 10     #@param {type:\"number\"}      # Number of denoising steps\n",
        "guidance_scale = 7.5        #@param {type:\"number\"}       # Scale for classifier-free guidance\n",
        "#batch_size = 2 #@param {type:\"number\"}\n",
        "# 画像のサイズ 512*512が初期値\n",
        "height = 512        #@param {type:\"number\"}              # default height of Stable Diffusion\n",
        "width = 512             #@param {type:\"number\"}          # default width of Stable Diffusion\n",
        "#batch_size = 1 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 描画指示\n",
        "\n",
        "#入力文字 ここに好きな禁則文字をいれてください\n",
        "\n",
        "prompt = \"masterpiece, ultra-detaled, best quality, A woman in a luxury dress with long hair with a beautiful and perfect symmetrical face blonde loose perm by mucha\" #@param {type:\"string\"}\n",
        "\n",
        "#ネガティブ 除外したい要素を入れる\n",
        "\n",
        "negative_prompt = \"pablo picasso,monet,dali,van gogh,\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "gwE8DaQ24Z0M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j8-Yu00JGMA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 画像生成回数とSEEDの種別\n",
        "\n",
        "N = 1 #@param {type:\"number\"}\n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = True #@param {'type':'boolean'}\n",
        "for i in range(N):\n",
        "# SEED値、ここをかえると 同じ入力文字でも別の画像がでます\n",
        "# seedを固定する時はseed_fixにチェック\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "  #VRAM消費を抑えたい場合有効に↓\n",
        "    pipe.enable_attention_slicing()\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    with torch.inference_mode():\n",
        "    #images = pipe(prompt, height = height, width = width, guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,negative_prompt = negative_prompt, generator = generator).images\n",
        "     images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples = 8,generator = generator).images\n",
        "#どのSEED値で描画されたか確認用\n",
        "     print(\"SEED =\",seed)\n",
        "     display(images[0])#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06TWdF3JQaA"
      },
      "source": [
        "もっと詳しく知りたい人は\n",
        "https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb#scrollTo=zHkHsdtnry57\n",
        "こっちのちゃんとしたcolabを見るんだ！！！！\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhfQ4GLv39K3"
      },
      "source": [
        "↓Waifu単独動作\n",
        "\n",
        "ここから動かせば良い。\n",
        "特に2次元はWifuが圧倒的"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye_11709e3Y0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        " #@title Waifu Diffusionのダウンロードと設定\n",
        " #!pip install diffusers==0.7.2 transformers scipy ftfy accelerate\n",
        "!pip install transformers scipy ftfy\n",
        "!pip install --upgrade diffusers[torch]\n",
        "\n",
        "#Xformersの実装をしたいけどよくわからんな\n",
        "# !sudo docker run -it --gpus=all --ipc=host -v /home:/home nvcr.io/nvidia/pytorch:22.08-py3 bash\n",
        "\n",
        "# Then \n",
        "# !pip install git+https://github.com/facebookresearch/xformers@51dd119#egg=xformers\n",
        "\n",
        "# Followed by\n",
        "# !cd PATH_TO_DIFFUSER_FOLDER\n",
        "# !git checkout memory_efficient_attention\n",
        "# !pip install -e . \n",
        "\n",
        "!git clone https://github.com/openai/triton.git\n",
        "%cd triton/python/\n",
        "!pip install -e .\n",
        "\n",
        "!pip install pytorch_lightning\n",
        "#とりあえずコンパイル済みこれ入れときゃ動くからいいか\n",
        "!pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4, should also work on P100, thanks to https://github.com/metrolobo\n",
        "\n",
        "#ランダム化したいので追加\n",
        "import random\n",
        "import torch\n",
        "#from diffusers.models import AutoencoderKL\n",
        "from torch import autocast\n",
        "#from diffusers import DiffusionPipeline\n",
        " from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler #DDIMScheduler\n",
        "# StableDiffusionパイプラインの準備\n",
        "# pipe = StableDiffusionPipeline.from_pretrained(\n",
        "#  \"hakurei/waifu-diffusion\",\n",
        "#  torch_dtype=torch.float32,\n",
        "  #revision=\"fp16\",#←最新バージョンで廃止されてる\n",
        "  #scheduler=DDIMScheduler(\n",
        "#vae = AutoencoderKL.from_pretrained(\"waifu-diffusion-v1-4/vae/kl-f8-anime.ckpt\")←仮 1.4リリース時に確認\n",
        "\n",
        " pipe = DiffusionPipeline.from_pretrained(\n",
        "    'hakurei/waifu-diffusion',   \n",
        "    custom_pipeline=\"lpw_stable_diffusion\",\n",
        "    #revision=\"fp32\",\n",
        "    torch_dtype=torch.float32,#vae=vae,\n",
        "  scheduler=LMSDiscreteScheduler(\n",
        "         beta_start=0.00085,\n",
        "         beta_end=0.012,\n",
        "         beta_schedule=\"scaled_linear\",\n",
        "         #.clip_sample=False,\n",
        "         #set_alpha_to_one=False,\n",
        "         num_train_timesteps=1000\n",
        "     ),\n",
        "     #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        "#NSFW回避処理\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "#VRAM低消費※少し実行速度が落ちる\n",
        "#pipe.enable_attention_slicing()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJTIRKLa_yfl"
      },
      "source": [
        "GUIでなくCUIで動くように直した。\n",
        "ループ組んで指定した回数実行し続けるのでこっちのほうが使い勝手よい。\n",
        "ランタイム切断でも再起動後継続する。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "num_inference_stepsは1~200\n",
        "\n",
        "回数が多い程綺麗になるが、極端に大きくしても変わらない\n",
        "\n",
        "推奨値は50\n",
        "\n",
        "guidance_scaleは1~20\n",
        "\n",
        "数値が大きい程Prompt内容に近くなるが多様性が無くなる\n",
        "\n",
        "推奨値は7〜8.5くらい、30超えると破綻する\n",
        "\n",
        "batch_size 増やすと施行数が増える?\n",
        "\n",
        "実行速度も上がるがVRAMを大量に消費\n",
        "\n",
        "基本的には512×512が1番良い結果が出る\n",
        "\n",
        "guidance_scale 1~30 大きい程promptに近い画像になるが多様性は無くなる"
      ],
      "metadata": {
        "id": "YDOetnwC1w1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 変数の設定\n",
        "\n",
        "#変数 初期値 512*512 scale:6 step:50\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "guidance_scale = 6 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "#batch_size = 1 #@param {type:\"number\"}\n",
        "#num_samples = 1 これは [prompt] * num_samplesで入れ子に指定回数分出力"
      ],
      "metadata": {
        "id": "gPL1RDhR0X_8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 描画指示\n",
        "prompt = \"cute cat ear maid\" #@param {type:\"string\"}\n",
        "\n",
        "negative_prompt = \"cat ear\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "LdLCkaac0sN_",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Dc8wK6oTpRt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ループ回数\n",
        "N = 1 #@param {type:\"number\"}\n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'} \n",
        "#ループ処理\n",
        "for i in range(N):\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "    pipe.enable_attention_slicing()\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    with torch.inference_mode():\n",
        "    #images = pipe(prompt, height = height, width = width, guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,negative_prompt = negative_prompt, generator = generator).images\n",
        "     images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples=8,generator = generator).images[0]\n",
        "\n",
        "#どのSEED値で描画されたか確認用\n",
        "     print(\"SEED =\",seed)\n",
        "     display(images)#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Gdriveからモデルデータを読込できるようにしたい\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!python -m venv .env\n",
        "\n",
        "!source .env/bin/activate\n",
        "\n",
        "!pip install diffusers==0.7.1 transformers scipy ftfy accelerate\n",
        "!pip install --upgrade diffusers transformers scipy\n",
        "#!huggingface-cli login\n",
        "import torch\n",
        "from torch import autocast\n",
        "# secretAI\n",
        "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
        "\n",
        "euler_ancestral_scheduler = EulerAncestralDiscreteScheduler.from_config(\"content/drive/MyDrive/model/novelAI.ckpt\", subfolder=\"scheduler\")\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "    \"content/drive/MyDrive/model/novelAI.ckpt\",torch_dtype=torch.float16, custom_pipeline=\"lpw_stable_diffusion\", scheduler=euler_scheduler, use_auth_token=YOUR_TOKEN,\n",
        ")\n",
        "pipeline.to(\"cuda\")"
      ],
      "metadata": {
        "id": "Z5cLeoAiY_fr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}